{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a8cc23-4a92-4025-9232-de88cc29d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    " \n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd0fbe-1782-4541-9685-59de03d4cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844c32c3-b6f8-429a-9941-05f0caca04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet input\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9952f389-96a0-4f38-8067-2f2d31c16a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"F:\\Dataset\\FoodSeg103_img\\IR\"\n",
    "\n",
    "data_train = datasets.ImageFolder(path, transform=transforms)\n",
    " \n",
    "data_loader = DataLoader(data_train, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a8d451-46e7-4df4-b3ad-2b67c4c5ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = datasets.ImageFolder(path, transform=transforms)\n",
    "\n",
    "# split ds init\n",
    "train_ratio = 0.8  # 80% for trainï¼Œ20% for test\n",
    "train_size = int(len(data_train) * train_ratio)\n",
    "test_size = len(data_train) - train_size\n",
    "\n",
    "# split\n",
    "train_dataset, test_dataset = random_split(data_train, [train_size, test_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803334bc-5acf-4fbf-bd6f-cf0dba557c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 18313\n",
      "Training images: 14650\n",
      "Testing images: 3663\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total images: {len(data_train)}\")\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Testing images: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205c168a-5c4a-4159-9a1b-ea0238edd9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18313\n"
     ]
    }
   ],
   "source": [
    "print(len(data_train))  # number of all image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "120a9e0b-60af-4e18-bb01-3244e1a43947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..1.7865399].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# random seclect\n",
    "random_idx = random.randint(0, len(train_dataset) - 1)  # random index\n",
    "image, label = train_dataset[random_idx]  # get image and label\n",
    "\n",
    "# visible\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image.permute(1, 2, 0))  # HWC\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b18e371-0b30-4ec1-a8e0-25b933deff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 103)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ffc6fc-1c88-4c3f-af8b-501e1c312e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9007e9e6-9747-4713-bb3b-5f5bc65ef3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nStarting Epoch {epoch + 1}/{num_epochs}...\")\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # f\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # b and op\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # cal acc\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # look process\n",
    "            if (batch_idx + 1) % 500 == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(train_loader)}], \"\n",
    "                      f\"Loss: {loss.item():.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "        \n",
    "        # look each epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch + 1} completed with Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c03c044-915c-4f17-87aa-de835cc7f92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Epoch 1/30...\n",
      "Epoch 1 completed with Loss: 2.2010, Accuracy: 46.71%\n",
      "\n",
      "Starting Epoch 2/30...\n",
      "Epoch 2 completed with Loss: 1.4239, Accuracy: 60.97%\n",
      "\n",
      "Starting Epoch 3/30...\n",
      "Epoch 3 completed with Loss: 1.1620, Accuracy: 67.00%\n",
      "\n",
      "Starting Epoch 4/30...\n",
      "Epoch 4 completed with Loss: 0.9751, Accuracy: 71.65%\n",
      "\n",
      "Starting Epoch 5/30...\n",
      "Epoch 5 completed with Loss: 0.8098, Accuracy: 75.75%\n",
      "\n",
      "Starting Epoch 6/30...\n",
      "Epoch 6 completed with Loss: 0.6772, Accuracy: 79.67%\n",
      "\n",
      "Starting Epoch 7/30...\n",
      "Epoch 7 completed with Loss: 0.5590, Accuracy: 83.09%\n",
      "\n",
      "Starting Epoch 8/30...\n",
      "Epoch 8 completed with Loss: 0.4662, Accuracy: 85.89%\n",
      "\n",
      "Starting Epoch 9/30...\n",
      "Epoch 9 completed with Loss: 0.3798, Accuracy: 88.68%\n",
      "\n",
      "Starting Epoch 10/30...\n",
      "Epoch 10 completed with Loss: 0.2991, Accuracy: 91.17%\n",
      "\n",
      "Starting Epoch 11/30...\n",
      "Epoch 11 completed with Loss: 0.2607, Accuracy: 92.17%\n",
      "\n",
      "Starting Epoch 12/30...\n",
      "Epoch 12 completed with Loss: 0.2319, Accuracy: 93.32%\n",
      "\n",
      "Starting Epoch 13/30...\n",
      "Epoch 13 completed with Loss: 0.1932, Accuracy: 94.42%\n",
      "\n",
      "Starting Epoch 14/30...\n",
      "Epoch 14 completed with Loss: 0.1897, Accuracy: 94.16%\n",
      "\n",
      "Starting Epoch 15/30...\n",
      "Epoch 15 completed with Loss: 0.1864, Accuracy: 94.35%\n",
      "\n",
      "Starting Epoch 16/30...\n",
      "Epoch 16 completed with Loss: 0.1436, Accuracy: 95.67%\n",
      "\n",
      "Starting Epoch 17/30...\n",
      "Epoch 17 completed with Loss: 0.1394, Accuracy: 95.86%\n",
      "\n",
      "Starting Epoch 18/30...\n",
      "Epoch 18 completed with Loss: 0.1124, Accuracy: 96.64%\n",
      "\n",
      "Starting Epoch 19/30...\n",
      "Epoch 19 completed with Loss: 0.1284, Accuracy: 96.08%\n",
      "\n",
      "Starting Epoch 20/30...\n",
      "Epoch 20 completed with Loss: 0.1250, Accuracy: 96.22%\n",
      "\n",
      "Starting Epoch 21/30...\n",
      "Epoch 21 completed with Loss: 0.1171, Accuracy: 96.45%\n",
      "\n",
      "Starting Epoch 22/30...\n",
      "Epoch 22 completed with Loss: 0.1361, Accuracy: 95.86%\n",
      "\n",
      "Starting Epoch 23/30...\n",
      "Epoch 23 completed with Loss: 0.1214, Accuracy: 96.44%\n",
      "\n",
      "Starting Epoch 24/30...\n",
      "Epoch 24 completed with Loss: 0.1154, Accuracy: 96.58%\n",
      "\n",
      "Starting Epoch 25/30...\n",
      "Epoch 25 completed with Loss: 0.0933, Accuracy: 97.24%\n",
      "\n",
      "Starting Epoch 26/30...\n",
      "Epoch 26 completed with Loss: 0.0855, Accuracy: 97.54%\n",
      "\n",
      "Starting Epoch 27/30...\n",
      "Epoch 27 completed with Loss: 0.0957, Accuracy: 96.98%\n",
      "\n",
      "Starting Epoch 28/30...\n",
      "Epoch 28 completed with Loss: 0.0976, Accuracy: 97.11%\n",
      "\n",
      "Starting Epoch 29/30...\n",
      "Epoch 29 completed with Loss: 0.0854, Accuracy: 97.48%\n",
      "\n",
      "Starting Epoch 30/30...\n",
      "Epoch 30 completed with Loss: 0.0929, Accuracy: 97.24%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b6d8acc-1d8f-4545-8997-962eebcb6e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 60.33%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_loader)\n",
    "\n",
    "# save\n",
    "torch.save(model.state_dict(), \"resnet50_foodseg103_50ep.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f89e2e-feef-457c-9380-4e40059932cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
